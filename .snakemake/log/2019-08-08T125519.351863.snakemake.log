Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 24
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	panphlan_map
	1

rule panphlan_map:
    input: /scr1/users/leej39/Sagori_RUN2/sunbeam_output/qc/decontam/SRC.738413_1.fastq.gz
    output: /scr1/users/leej39/Sagori_RUN2/PanPhlAn_output/map_result/SRC.738413_ecoli16.csv.bz2
    jobid: 0
    wildcards: sample=SRC.738413, clade=ecoli16


        ~/panphlan/panphlan_map.py         -c ecoli16         -i /scr1/users/leej39/Sagori_RUN2/sunbeam_output/qc/decontam/SRC.738413_1.fastq.gz         --output /scr1/users/leej39/Sagori_RUN2/PanPhlAn_output/map_result/SRC.738413_ecoli16.csv         --verbose
        
Finished job 0.
1 of 1 steps (100%) done
Shutting down, this might take some time.
Complete log: /home/leej39/pan_snake/.snakemake/log/2019-08-08T125519.351863.snakemake.log
